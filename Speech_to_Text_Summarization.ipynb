{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJG081Jp1fR_",
        "outputId": "c1ed0768-fdf3-4eb9-c2c6-dd332a968178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in c:\\python312\\lib\\site-packages (15.0.0)"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
            "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\tqdm.exe' -> 'C:\\\\Python312\\\\Scripts\\\\tqdm.exe.deleteme'\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: torch in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (0.17.2)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.3.1-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "     ---------------------------------------- 0.0/798.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/798.6 kB ? eta -:--:--\n",
            "      --------------------------------------- 10.2/798.6 kB ? eta -:--:--\n",
            "     ---- ---------------------------------- 92.2/798.6 kB 1.3 MB/s eta 0:00:01\n",
            "     ----------------------- -------------- 491.5/798.6 kB 3.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  788.5/798.6 kB 5.0 MB/s eta 0:00:01\n",
            "     -------------------------------------- 798.6/798.6 kB 4.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
            "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 43.8/43.8 kB 2.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (10.3.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.3.0-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.2.2-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
            "Collecting numba (from openai-whisper)\n",
            "  Downloading numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
            "Collecting tqdm (from openai-whisper)\n",
            "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting more-itertools (from openai-whisper)\n",
            "  Using cached more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting colorama (from tqdm->openai-whisper)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abidheep2520\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
            "  Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Using cached certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torchaudio-2.2.2-cp312-cp312-win_amd64.whl (2.4 MB)\n",
            "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 0.5/2.4 MB 9.4 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 0.9/2.4 MB 9.8 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.0/2.4 MB 9.4 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.0/2.4 MB 9.4 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.0/2.4 MB 9.4 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.1/2.4 MB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.4 MB 5.0 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.1/2.4 MB 5.5 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.1/2.4 MB 5.5 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.1/2.4 MB 5.5 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.1/2.4 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.3/2.4 MB 4.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.4/2.4 MB 3.8 MB/s eta 0:00:00\n",
            "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 0.7/9.1 MB 23.1 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.4/9.1 MB 17.6 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 1.9/9.1 MB 15.2 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 2.5/9.1 MB 14.5 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 3.1/9.1 MB 13.9 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 3.7/9.1 MB 13.8 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 4.4/9.1 MB 14.0 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 5.0/9.1 MB 14.0 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 5.7/9.1 MB 13.9 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 6.3/9.1 MB 13.8 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 6.9/9.1 MB 13.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 7.6/9.1 MB 13.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.3/9.1 MB 13.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.0/9.1 MB 14.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.1/9.1 MB 13.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.1/9.1 MB 12.9 MB/s eta 0:00:00\n",
            "Using cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
            "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
            "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 268.5/268.5 kB 8.1 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
            "   ---------------------------------------- 0.0/289.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 289.4/289.4 kB 8.7 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 0.5/2.2 MB 16.5 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.4/2.2 MB 18.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 2.1/2.2 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 14.1 MB/s eta 0:00:00\n",
            "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "Downloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
            "   ---------------------------------------- 0.0/59.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 59.2/59.2 kB 3.1 MB/s eta 0:00:00\n",
            "Downloading numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
            "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 0.8/2.7 MB 16.3 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.6/2.7 MB 16.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 2.3/2.7 MB 15.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.7/2.7 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.7/2.7 MB 14.3 MB/s eta 0:00:00\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl (799 kB)\n",
            "   ---------------------------------------- 0.0/799.3 kB ? eta -:--:--\n",
            "   ------------------------------- ------- 645.1/799.3 kB 20.5 MB/s eta 0:00:01\n",
            "   --------------------------------------- 799.3/799.3 kB 12.7 MB/s eta 0:00:00\n",
            "Using cached certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
            "Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
            "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.6/28.1 MB 13.1 MB/s eta 0:00:03\n",
            "   - -------------------------------------- 1.2/28.1 MB 13.1 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 1.9/28.1 MB 13.8 MB/s eta 0:00:02\n",
            "   --- ------------------------------------ 2.5/28.1 MB 14.4 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 3.2/28.1 MB 14.6 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 3.8/28.1 MB 13.6 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 4.5/28.1 MB 14.3 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 5.2/28.1 MB 14.4 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 5.6/28.1 MB 13.9 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 6.1/28.1 MB 13.4 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 6.6/28.1 MB 13.2 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 7.3/28.1 MB 13.3 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 7.9/28.1 MB 13.2 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 8.3/28.1 MB 13.0 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 8.7/28.1 MB 12.6 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 9.1/28.1 MB 12.4 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 9.5/28.1 MB 12.2 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 10.2/28.1 MB 12.3 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 11.0/28.1 MB 12.4 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 11.7/28.1 MB 12.6 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 12.5/28.1 MB 12.6 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 13.2/28.1 MB 12.9 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 13.9/28.1 MB 12.8 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 14.7/28.1 MB 12.8 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 15.2/28.1 MB 12.6 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 15.7/28.1 MB 12.6 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 16.4/28.1 MB 13.1 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 17.1/28.1 MB 13.1 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 17.5/28.1 MB 12.8 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 18.0/28.1 MB 12.9 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 18.4/28.1 MB 12.6 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 18.8/28.1 MB 12.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 19.3/28.1 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 19.9/28.1 MB 13.1 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 20.5/28.1 MB 12.8 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 21.1/28.1 MB 12.8 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 21.7/28.1 MB 12.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 22.4/28.1 MB 12.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 23.0/28.1 MB 12.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 23.5/28.1 MB 12.1 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 24.3/28.1 MB 12.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 25.0/28.1 MB 12.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 25.8/28.1 MB 12.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 26.4/28.1 MB 12.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 27.0/28.1 MB 12.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  27.8/28.1 MB 12.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  28.1/28.1 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  28.1/28.1 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 28.1/28.1 MB 11.3 MB/s eta 0:00:00\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml): started\n",
            "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801375 sha256=01d232b3b9082398722e8560b7beeec5fc7fc9712a74b705a81c84fcf72e8ce1\n",
            "  Stored in directory: c:\\users\\abidheep2520\\appdata\\local\\pip\\cache\\wheels\\55\\ec\\14\\404c547d6e1de602b5ca15043eeed769aaa07e22dd34460456\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: safetensors, regex, more-itertools, llvmlite, colorama, certifi, tqdm, requests, numba, torchaudio, tiktoken, huggingface-hub, tokenizers, openai-whisper, transformers\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube torch torchvision torchaudio openai-whisper transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqvGoHQGySu1",
        "outputId": "6cc20b9d-4a4c-48c7-b741-f5bab8802f26"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytube'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytube\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YouTube\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Download YouTube Video and Extract Audio\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytube'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "import whisper\n",
        "\n",
        "# Download YouTube Video and Extract Audio\n",
        "def download_youtube_audio(url, output_path='audio.mp4'):\n",
        "    yt = YouTube(url)\n",
        "    video = yt.streams.filter(only_audio=True).first()\n",
        "    audio_file = video.download(filename=output_path)\n",
        "    return audio_file\n",
        "\n",
        "# Convert Speech to Text using Whisper\n",
        "def speech_to_text(audio_path):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result['text']\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    youtube_url = 'https://youtu.be/X2huNCHDwMQ?si=XoHoOQWb7trbI09g'\n",
        "    audio_path = download_youtube_audio(youtube_url)\n",
        "    transcript = speech_to_text(audio_path)\n",
        "    print(\"Transcript:\", transcript)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmN55ZIr-a09",
        "outputId": "5275b04d-b6eb-400e-ae81-5712ef6ee89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th3F31zQ7sP_",
        "outputId": "c9c7ecee-f914-44da-e1ee-7b857f04296b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary using BART:\n",
            "If you have zero views on your channel, your first video is not going to give you. Period. So stop sitting there and thinking for months and months on end and just get to work and start uploading. There's literally no such thing as a perfect video. Don't really worry about what your niche is like people get hung up on this like I don't know what to make videos about.\n",
            "\n",
            "Summary using BERTSum:\n",
            "this applies to people that not upload videos, but have dreams of being a youtuber. here's some amazing youtube advice from 10 very successful youtubers. you'll get into number one if you have zero views on your 101st video. you can't expect a perfect video, but you're not going to write a new one. there's literally no such thing as perfect video.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer, EncoderDecoderModel, BertTokenizer\n",
        "\n",
        "def summarize_text(text, model_name=\"facebook/bart-large-cnn\"):\n",
        "    if model_name.startswith(\"facebook/bart\"):\n",
        "        tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "        model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "        inputs = tokenizer(text, max_length=1024, return_tensors='pt', truncation=True)\n",
        "        summary_ids = model.generate(\n",
        "            inputs['input_ids'],\n",
        "            max_length=150,\n",
        "            min_length=80,\n",
        "            length_penalty=2.0,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    elif model_name.startswith(\"bert\"):\n",
        "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
        "        inputs = tokenizer(text, max_length=512, return_tensors='pt', truncation=True)\n",
        "        summary_ids = model.generate(\n",
        "            inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            max_length=150,\n",
        "            min_length=80,\n",
        "            length_penalty=2.0,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model_name. Choose 'facebook/bart-' or 'bert-'\")\n",
        "\n",
        "    return summary\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    summary_bart = summarize_text(transcript, model_name=\"facebook/bart-large-cnn\")\n",
        "    print(\"Summary using BART:\")\n",
        "    print(summary_bart)\n",
        "\n",
        "    summary_bertsum = summarize_text(transcript, model_name=\"bert-base-uncased\")\n",
        "    print(\"\\nSummary using BERTSum:\")\n",
        "    print(summary_bertsum)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
